#!/usr/bin/env python3
"""
Test script for error handling and recovery functionality.
"""

import asyncio
import tempfile
import os
import logging
import hashlib
from pathlib import Path
from unittest.mock import patch, MagicMock

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import services
from services.file_upload_service import file_upload_service
from services.database_service import database_service


class MockUploadFile:
    """Mock UploadFile for testing."""
    
    def __init__(self, filename: str, content: bytes, content_type: str = "text/plain"):
        self.filename = filename
        self.content = content
        self.content_type = content_type
        self.size = len(content)
    
    async def read(self) -> bytes:
        return self.content


async def test_hash_calculation_fallback():
    """Test hash calculation fallback mechanisms."""
    
    logger.info("ğŸ§ª í•´ì‹œ ê³„ì‚° ëŒ€ì²´ ë¡œì§ í…ŒìŠ¤íŠ¸")
    
    test_content = b"Test content for hash fallback testing"
    
    # Test 1: Normal hash calculation
    normal_hash = file_upload_service._calculate_file_hash(test_content)
    logger.info(f"ì •ìƒ í•´ì‹œ: {normal_hash}")
    assert len(normal_hash) == 64  # SHA-256 hex length
    
    # Test 2: Simulate SHA-256 failure
    with patch('hashlib.sha256') as mock_sha256:
        mock_sha256.side_effect = Exception("SHA-256 calculation failed")
        
        fallback_hash = file_upload_service._calculate_file_hash(test_content)
        logger.info(f"ëŒ€ì²´ í•´ì‹œ: {fallback_hash}")
        assert fallback_hash.startswith("md5_")
    
    # Test 3: Simulate both SHA-256 and MD5 failure
    with patch('hashlib.sha256') as mock_sha256, patch('hashlib.md5') as mock_md5:
        mock_sha256.side_effect = Exception("SHA-256 failed")
        mock_md5.side_effect = Exception("MD5 failed")
        
        emergency_hash = file_upload_service._calculate_file_hash(test_content)
        logger.info(f"ë¹„ìƒ ì‹ë³„ì: {emergency_hash}")
        assert emergency_hash.startswith("fallback_")
    
    logger.info("âœ… í•´ì‹œ ê³„ì‚° ëŒ€ì²´ ë¡œì§ í…ŒìŠ¤íŠ¸ í†µê³¼")


async def test_upload_error_recovery():
    """Test file upload error recovery."""
    
    logger.info("ğŸ§ª íŒŒì¼ ì—…ë¡œë“œ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸")
    
    test_content = b"Test content for upload error recovery"
    mock_file = MockUploadFile("test_error_recovery.txt", test_content)
    
    # Test 1: Database storage failure simulation
    with patch.object(database_service, 'store_file', return_value=False):
        result = await file_upload_service.upload_file(mock_file)
        
        logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨ ì‹œ ê²°ê³¼: {result['success']}")
        assert result["success"] == False
        assert "Database storage failed" in result["error"]
    
    logger.info("âœ… íŒŒì¼ ì—…ë¡œë“œ ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_data_consistency_check():
    """Test data consistency verification."""
    
    logger.info("ğŸ§ª ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬ í…ŒìŠ¤íŠ¸")
    
    # Run consistency check
    result = database_service.verify_data_consistency()
    
    logger.info(f"ì¼ê´€ì„± ê²€ì‚¬ ê²°ê³¼: {result}")
    assert "consistent" in result
    assert "issues_found" in result
    assert "checked_at" in result
    
    if not result["consistent"]:
        logger.info(f"ë°œê²¬ëœ ë¬¸ì œ: {result['issues_found']}ê°œ")
        for issue in result.get("issues", []):
            logger.info(f"  - {issue['type']}: {issue['count']}ê°œ")
    
    logger.info("âœ… ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_data_repair_dry_run():
    """Test data repair in dry run mode."""
    
    logger.info("ğŸ§ª ë°ì´í„° ë³µêµ¬ ë“œë¼ì´ ëŸ° í…ŒìŠ¤íŠ¸")
    
    # Run repair in dry run mode
    result = database_service.repair_data_inconsistencies(dry_run=True)
    
    logger.info(f"ë“œë¼ì´ ëŸ° ê²°ê³¼: {result}")
    assert "success" in result
    assert result["dry_run"] == True
    assert "repairs_performed" in result
    
    if result["repairs_performed"] > 0:
        logger.info(f"ìˆ˜í–‰ ê°€ëŠ¥í•œ ë³µêµ¬: {result['repairs_performed']}ê°œ")
        for repair in result.get("repairs", []):
            logger.info(f"  - {repair['type']}: {repair['count']}ê°œ ({repair['action']})")
    else:
        logger.info("ë³µêµ¬ê°€ í•„ìš”í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
    
    logger.info("âœ… ë°ì´í„° ë³µêµ¬ ë“œë¼ì´ ëŸ° í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_fallback_identifier_generation():
    """Test fallback identifier generation."""
    
    logger.info("ğŸ§ª ëŒ€ì²´ ì‹ë³„ì ìƒì„± í…ŒìŠ¤íŠ¸")
    
    # Test with various inputs
    test_cases = [
        ("normal_file.txt", 1024, 1234567890.123),
        ("file with spaces.pdf", 2048, 1234567890.456),
        ("íŒŒì¼ëª…í•œê¸€.docx", 4096, 1234567890.789),
        ("very_long_filename_that_should_be_truncated_to_reasonable_length.txt", 8192, 1234567890.999)
    ]
    
    for filename, size, timestamp in test_cases:
        identifier = file_upload_service._generate_fallback_identifier(filename, size, timestamp)
        logger.info(f"íŒŒì¼: {filename} -> ì‹ë³„ì: {identifier}")
        
        assert identifier.startswith("fallback_")
        assert str(size) in identifier
        assert len(identifier) < 200  # Reasonable length limit
    
    logger.info("âœ… ëŒ€ì²´ ì‹ë³„ì ìƒì„± í…ŒìŠ¤íŠ¸ í†µê³¼")


async def test_database_transaction_rollback():
    """Test database transaction rollback on errors."""
    
    logger.info("ğŸ§ª ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ ë¡¤ë°± í…ŒìŠ¤íŠ¸")
    
    # This test would require more complex setup to properly test rollback
    # For now, we'll just verify the rollback mechanism exists
    
    try:
        # Simulate a transaction that should fail
        with database_service.get_connection() as conn:
            conn.execute("BEGIN TRANSACTION")
            # This would be where we'd test actual rollback scenarios
            conn.execute("ROLLBACK")
        
        logger.info("íŠ¸ëœì­ì…˜ ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜ í™•ì¸ë¨")
    except Exception as e:
        logger.error(f"íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        raise
    
    logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ ë¡¤ë°± í…ŒìŠ¤íŠ¸ í†µê³¼")


async def main():
    """Run all error handling tests."""
    
    logger.info("ğŸš€ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    tests = [
        ("í•´ì‹œ ê³„ì‚° ëŒ€ì²´ ë¡œì§", test_hash_calculation_fallback),
        ("íŒŒì¼ ì—…ë¡œë“œ ì—ëŸ¬ ë³µêµ¬", test_upload_error_recovery),
        ("ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬", test_data_consistency_check),
        ("ë°ì´í„° ë³µêµ¬ ë“œë¼ì´ ëŸ°", test_data_repair_dry_run),
        ("ëŒ€ì²´ ì‹ë³„ì ìƒì„±", test_fallback_identifier_generation),
        ("ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëœì­ì…˜ ë¡¤ë°±", test_database_transaction_rollback)
    ]
    
    results = []
    
    for test_name, test_func in tests:
        try:
            logger.info(f"\n{'='*50}")
            logger.info(f"í…ŒìŠ¤íŠ¸: {test_name}")
            logger.info(f"{'='*50}")
            
            if asyncio.iscoroutinefunction(test_func):
                await test_func()
            else:
                test_func()
            
            results.append((test_name, True))
            logger.info(f"âœ… {test_name} í†µê³¼")
            
        except Exception as e:
            logger.error(f"âŒ {test_name} ì‹¤íŒ¨: {str(e)}")
            results.append((test_name, False))
    
    # Summary
    logger.info(f"\n{'='*50}")
    logger.info("ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info(f"{'='*50}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"{test_name}: {status}")
    
    logger.info(f"\nì´ {total}ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ {passed}ê°œ í†µê³¼ ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ ëª¨ë“  ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
    else:
        logger.error(f"âš ï¸ {total - passed}ê°œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
