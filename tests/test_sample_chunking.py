#!/usr/bin/env python3
"""Test text chunking functionality with sample document."""

import requests
import json
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


def load_sample_document():
    """Load the sample document."""
    try:
        with open('sample_docs/ê¸°ì—… ë¬¸ì„œ ê²€ìƒ‰ ë„êµ¬ ë¶„ì„.md', 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except FileNotFoundError:
        print("âŒ Sample document not found!")
        return None


def test_chunking_with_sample():
    """Test KURE API chunking functionality with sample document."""
    
    print("ğŸ§ª Testing KURE API Text Chunking with Sample Document")
    print("=" * 70)
    
    # Load sample document
    sample_text = load_sample_document()
    if not sample_text:
        return False
    
    print(f"ğŸ“„ Loaded sample document: {len(sample_text)} characters")
    print(f"ğŸ“„ First 200 chars: {sample_text[:200]}...")
    
    # Get configuration from environment
    api_key = os.getenv("API_KEY", "sk-kure-v1-test-key-12345")
    base_url = os.getenv("BASE_URL", "http://localhost:8000")
    
    print(f"ğŸ”‘ Using API Key: {api_key[:20]}...")
    print(f"ğŸŒ Base URL: {base_url}")
    
    # Headers with Bearer token
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Test 1: Korean sentence chunking with medium chunks
    print("\n1. ğŸ“ Testing Korean sentence chunking (medium chunks)...")
    try:
        payload = {
            "text": sample_text,
            "strategy": "sentence",
            "chunk_size": 300,
            "overlap": 50,
            "language": "ko"
        }
        
        response = requests.post(f"{base_url}/v1/chunk", json=payload, headers=headers)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Total chunks: {data['total_chunks']}")
            print(f"âœ… Strategy used: {data['strategy']}")
            print(f"âœ… Original length: {data['original_length']} chars")
            print(f"âœ… Total tokens: {data['total_tokens']}")
            
            # Show first 3 chunks
            for i, chunk in enumerate(data['data'][:3]):
                print(f"\n  ğŸ“‹ Chunk {i}:")
                print(f"    Tokens: {chunk['token_count']}")
                print(f"    Position: chars {chunk['start_char']}-{chunk['end_char']}")
                print(f"    Text: {chunk['text'][:150]}...")
                
            # Show statistics
            token_counts = [chunk['token_count'] for chunk in data['data']]
            print(f"\n  ğŸ“Š Chunk Statistics:")
            print(f"    Min tokens: {min(token_counts)}")
            print(f"    Max tokens: {max(token_counts)}")
            print(f"    Avg tokens: {sum(token_counts) / len(token_counts):.1f}")
            
        else:
            print(f"âŒ Korean sentence chunking failed: {response.text}")
            
    except Exception as e:
        print(f"âŒ Korean sentence chunking error: {e}")
    
    # Test 2: Recursive chunking with smaller chunks
    print("\n2. ğŸ”„ Testing recursive chunking (smaller chunks)...")
    try:
        payload = {
            "text": sample_text,
            "strategy": "recursive",
            "chunk_size": 200,
            "overlap": 30,
            "language": "ko"
        }
        
        response = requests.post(f"{base_url}/v1/chunk", json=payload, headers=headers)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Total chunks: {data['total_chunks']}")
            print(f"âœ… Strategy used: {data['strategy']}")
            print(f"âœ… Total tokens: {data['total_tokens']}")
            
            # Show first 3 chunks
            for i, chunk in enumerate(data['data'][:3]):
                print(f"\n  ğŸ“‹ Chunk {i}:")
                print(f"    Tokens: {chunk['token_count']}")
                print(f"    Position: chars {chunk['start_char']}-{chunk['end_char']}")
                print(f"    Text: {chunk['text'][:100]}...")
                
        else:
            print(f"âŒ Recursive chunking failed: {response.text}")
            
    except Exception as e:
        print(f"âŒ Recursive chunking error: {e}")
    
    # Test 3: Token-based chunking with large chunks
    print("\n3. ğŸ¯ Testing token-based chunking (large chunks)...")
    try:
        payload = {
            "text": sample_text,
            "strategy": "token",
            "chunk_size": 500,
            "overlap": 75,
            "language": "auto"
        }
        
        response = requests.post(f"{base_url}/v1/chunk", json=payload, headers=headers)
        print(f"Status: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… Total chunks: {data['total_chunks']}")
            print(f"âœ… Strategy used: {data['strategy']}")
            print(f"âœ… Total tokens: {data['total_tokens']}")
            
            # Show first 2 chunks
            for i, chunk in enumerate(data['data'][:2]):
                print(f"\n  ğŸ“‹ Chunk {i}:")
                print(f"    Tokens: {chunk['token_count']}")
                print(f"    Position: chars {chunk['start_char']}-{chunk['end_char']}")
                print(f"    Text: {chunk['text'][:120]}...")
                
        else:
            print(f"âŒ Token chunking failed: {response.text}")
            
    except Exception as e:
        print(f"âŒ Token chunking error: {e}")
    
    # Test 4: Compare strategies with same chunk size
    print("\n4. ğŸ“Š Comparing all strategies with same parameters...")
    try:
        strategies = ["sentence", "recursive", "token"]
        results = {}
        
        for strategy in strategies:
            payload = {
                "text": sample_text[:5000],  # Use first 5000 chars for comparison
                "strategy": strategy,
                "chunk_size": 250,
                "overlap": 40,
                "language": "ko"
            }
            
            response = requests.post(f"{base_url}/v1/chunk", json=payload, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                results[strategy] = {
                    "total_chunks": data['total_chunks'],
                    "total_tokens": data['total_tokens'],
                    "avg_tokens": data['total_tokens'] / data['total_chunks']
                }
            else:
                results[strategy] = {"error": response.text}
        
        print("\n  ğŸ“ˆ Strategy Comparison Results:")
        print("  " + "-" * 60)
        print(f"  {'Strategy':<12} {'Chunks':<8} {'Tokens':<8} {'Avg/Chunk':<10}")
        print("  " + "-" * 60)
        
        for strategy, result in results.items():
            if "error" not in result:
                print(f"  {strategy:<12} {result['total_chunks']:<8} {result['total_tokens']:<8} {result['avg_tokens']:<10.1f}")
            else:
                print(f"  {strategy:<12} ERROR")
                
    except Exception as e:
        print(f"âŒ Strategy comparison error: {e}")
    
    # Test 5: Test with section of document (specific content)
    print("\n5. ğŸ“‘ Testing with specific document section...")
    try:
        # Extract a specific section (market analysis)
        section_start = sample_text.find("## **2. ì‹œì¥ì„± ë¶„ì„")
        section_end = sample_text.find("## **3. ê¸°ëŠ¥ ê°œìš”")
        
        if section_start != -1 and section_end != -1:
            section_text = sample_text[section_start:section_end]
            print(f"ğŸ“„ Extracted section: {len(section_text)} characters")
            
            payload = {
                "text": section_text,
                "strategy": "sentence",
                "chunk_size": 400,
                "overlap": 60,
                "language": "ko"
            }
            
            response = requests.post(f"{base_url}/v1/chunk", json=payload, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… Section chunks: {data['total_chunks']}")
                print(f"âœ… Section tokens: {data['total_tokens']}")
                
                # Show all chunks for this section
                for i, chunk in enumerate(data['data']):
                    print(f"\n  ğŸ“‹ Section Chunk {i}:")
                    print(f"    Tokens: {chunk['token_count']}")
                    print(f"    Text: {chunk['text'][:100]}...")
            else:
                print(f"âŒ Section chunking failed: {response.text}")
        else:
            print("âŒ Could not find market analysis section")
            
    except Exception as e:
        print(f"âŒ Section chunking error: {e}")
    
    print("\nğŸ‰ Sample Document Chunking Test Completed!")
    return True


if __name__ == "__main__":
    test_chunking_with_sample()
