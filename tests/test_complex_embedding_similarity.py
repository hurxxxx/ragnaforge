#!/usr/bin/env python3
"""
ë³µì¡í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸ ê°„ ìœ ì‚¬ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ì–‘í•œ ë³µì¡ì„±ê³¼ ì˜ë¯¸ì  ë‰˜ì•™ìŠ¤ë¥¼ ê°€ì§„ ë¬¸ì¥ë“¤ì„ ì‚¬ìš©í•˜ì—¬
ì„ë² ë”© ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµí•©ë‹ˆë‹¤.
"""

import asyncio
import json
import logging
import numpy as np
import time
from typing import Dict, List, Tuple, Any
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import pearsonr, spearmanr

from services.embedding_service import embedding_service
from config import settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ComplexEmbeddingSimilarityTest:
    """ë³µì¡í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•œ ì„ë² ë”© ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.models = [
            "dragonkue/snowflake-arctic-embed-l-v2.0-ko",
            "nlpai-lab/KURE-v1"
        ]
        
        # ë³µì¡í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì¥ë“¤ ì •ì˜
        self.test_scenarios = self._define_test_scenarios()
        
    def _define_test_scenarios(self) -> Dict[str, List[Tuple[str, str, float]]]:
        """ë³µì¡í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        
        scenarios = {
            "ê¸°ìˆ _ë¬¸ì„œ_ìœ ì‚¬ì„±": [
                (
                    "ì¸ê³µì§€ëŠ¥ ê¸°ë°˜ì˜ ìì—°ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆë‹¤.",
                    "ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ NLP ê¸°ìˆ ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ë¬¸ë§¥ì„ íŒŒì•…í•˜ê³  ì–¸ì–´ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.",
                    0.8  # ë†’ì€ ìœ ì‚¬ë„ ê¸°ëŒ€
                ),
                (
                    "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ê³ ì°¨ì› ë²¡í„° ê³µê°„ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ íŠ¹ìˆ˜í•œ ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œì´ë‹¤.",
                    "ì„ë² ë”© ì €ì¥ì†ŒëŠ” ë‹¤ì°¨ì› ë²¡í„°ë“¤ì„ ì¸ë±ì‹±í•˜ì—¬ ë¹ ë¥¸ ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ë°ì´í„° ê´€ë¦¬ ì†”ë£¨ì…˜ì´ë‹¤.",
                    0.75  # ë†’ì€ ìœ ì‚¬ë„ ê¸°ëŒ€
                ),
                (
                    "RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì€ ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìƒì„± ëª¨ë¸ì˜ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì´ë‹¤.",
                    "ê²€ìƒ‰ ì¦ê°• ìƒì„± ëª¨ë¸ì€ ë¬¸ì„œ ì €ì¥ì†Œì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ ë” ì •í™•í•˜ê³  ì‚¬ì‹¤ì ì¸ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” AI ê¸°ìˆ ì´ë‹¤.",
                    0.85  # ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„ ê¸°ëŒ€
                )
            ],
            
            "ë¹„ì¦ˆë‹ˆìŠ¤_ë¬¸ë§¥_ì´í•´": [
                (
                    "ìš°ë¦¬ íšŒì‚¬ì˜ ë¶„ê¸°ë³„ ë§¤ì¶œ ì„±ì¥ë¥ ì´ ì „ë…„ ë™ê¸° ëŒ€ë¹„ 15% ì¦ê°€í–ˆìœ¼ë©°, ì´ëŠ” ì£¼ë¡œ ì‹ ì œí’ˆ ì¶œì‹œì™€ ë§ˆì¼€íŒ… ì „ëµì˜ ì„±ê³µì— ê¸°ì¸í•œë‹¤.",
                    "ì´ë²ˆ ë¶„ê¸° ìˆ˜ìµì´ ì‘ë…„ ê°™ì€ ê¸°ê°„ë³´ë‹¤ 15% ëŠ˜ì–´ë‚¬ëŠ”ë°, ìƒˆë¡œìš´ ìƒí’ˆ ëŸ°ì¹­ê³¼ íš¨ê³¼ì ì¸ ê´‘ê³  ìº í˜ì¸ì´ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ë¶„ì„ëœë‹¤.",
                    0.8
                ),
                (
                    "ê³ ê° ë§Œì¡±ë„ ì¡°ì‚¬ ê²°ê³¼, ì„œë¹„ìŠ¤ í’ˆì§ˆì— ëŒ€í•œ í‰ê°€ëŠ” ê¸ì •ì ì´ì—ˆìœ¼ë‚˜ ë°°ì†¡ ì‹œê°„ê³¼ ê´€ë ¨ëœ ë¶ˆë§Œì´ ì§€ì†ì ìœ¼ë¡œ ì œê¸°ë˜ê³  ìˆë‹¤.",
                    "ì†Œë¹„ì ì„¤ë¬¸ì¡°ì‚¬ì—ì„œ ì œí’ˆ í€„ë¦¬í‹°ëŠ” ì¢‹ì€ í‰ê°€ë¥¼ ë°›ì•˜ì§€ë§Œ, ë°°ì†¡ ì§€ì—° ë¬¸ì œì— ëŒ€í•œ ê°œì„  ìš”êµ¬ê°€ ê³„ì† ë‚˜ì˜¤ê³  ìˆë‹¤.",
                    0.75
                ),
                (
                    "ë””ì§€í„¸ íŠ¸ëœìŠ¤í¬ë©”ì´ì…˜ í”„ë¡œì íŠ¸ì˜ ì¼í™˜ìœ¼ë¡œ í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì¶”ì§„í•˜ì—¬ ìš´ì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê³  ë¹„ìš©ì„ ì ˆê°í•  ê³„íšì´ë‹¤.",
                    "íšŒì‚¬ì˜ ë””ì§€í„¸ í˜ì‹  ê³„íšì— ë”°ë¼ ì‹œìŠ¤í…œì„ í´ë¼ìš°ë“œë¡œ ì´ì „í•˜ì—¬ ì—…ë¬´ íš¨ìœ¨ì„ ê°œì„ í•˜ê³  ìš´ì˜ë¹„ë¥¼ ì¤„ì´ë ¤ê³  í•œë‹¤.",
                    0.82
                )
            ],
            
            "í•™ìˆ _ë…¼ë¬¸_ìŠ¤íƒ€ì¼": [
                (
                    "ë³¸ ì—°êµ¬ì—ì„œëŠ” ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì´ìš©í•œ ë‹¤ì¤‘ ëª¨ë‹¬ ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì œì•ˆí•˜ë©°, í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ìœµí•©í•˜ì—¬ ê°ì • ì¸ì‹ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ë¡ ì„ ì œì‹œí•œë‹¤.",
                    "ì´ ë…¼ë¬¸ì€ ë”¥ëŸ¬ë‹ ê¸°ë°˜ì˜ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ë¥˜ ì‹œìŠ¤í…œì„ ê°œë°œí•˜ì˜€ìœ¼ë©°, ì–¸ì–´ì  íŠ¹ì§•ê³¼ ì‹œê°ì  íŠ¹ì§•ì„ ê²°í•©í•˜ì—¬ ê°ì • íŒë³„ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ì ‘ê·¼ë²•ì„ ì†Œê°œí•œë‹¤.",
                    0.85
                ),
                (
                    "ì‹¤í—˜ ê²°ê³¼, ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ì€ ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ëŒ€ë¹„ F1-scoreì—ì„œ 12.3% í–¥ìƒëœ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°, íŠ¹íˆ ë¶€ì •ì  ê°ì • ë¶„ë¥˜ì—ì„œ ë›°ì–´ë‚œ ì„±ê³¼ë¥¼ ë‚˜íƒ€ëƒˆë‹¤.",
                    "ì„±ëŠ¥ í‰ê°€ì—ì„œ ìš°ë¦¬ê°€ ê°œë°œí•œ ë°©ë²•ì€ ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ F1 ì ìˆ˜ê°€ 12.3% ë†’ì•˜ê³ , íŠ¹íˆ ë„¤ê±°í‹°ë¸Œ ê°ì •ì„ êµ¬ë¶„í•˜ëŠ” ë° ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆë‹¤.",
                    0.8
                )
            ],
            
            "ì¼ìƒ_ëŒ€í™”_vs_ì „ë¬¸ìš©ì–´": [
                (
                    "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ì‚°ì±…í•˜ê¸° ë”± ì¢‹ì€ ê²ƒ ê°™ì•„ìš”.",
                    "ê¸°ìƒ ì¡°ê±´ì´ ë§¤ìš° ì–‘í˜¸í•˜ì—¬ ì•¼ì™¸ í™œë™ì— ì í•©í•œ í™˜ê²½ì´ ì¡°ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    0.6  # ì¤‘ê°„ ì •ë„ ìœ ì‚¬ë„
                ),
                (
                    "ì»´í“¨í„°ê°€ ê°‘ìê¸° ëŠë ¤ì ¸ì„œ ì‘ì—…í•˜ê¸° í˜ë“¤ì–´ìš”.",
                    "ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜ë¡œ ì¸í•´ ì—…ë¬´ íš¨ìœ¨ì„±ì´ í˜„ì €íˆ ê°ì†Œí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    0.7
                ),
                (
                    "ì´ ìŒì‹ ì •ë§ ë§›ìˆë‹¤! ë˜ ë¨¹ê³  ì‹¶ì–´.",
                    "ë³¸ ìš”ë¦¬ì˜ í’ë¯¸ê°€ íƒì›”í•˜ì—¬ ì¬ì„­ì·¨ ì˜í–¥ì´ ë†’ìŠµë‹ˆë‹¤.",
                    0.65
                )
            ],
            
            "ë¶€ì •_ë¬¸ì¥_vs_ê¸ì •_ë¬¸ì¥": [
                (
                    "ì´ ì œí’ˆì€ í’ˆì§ˆì´ ë§¤ìš° ìš°ìˆ˜í•˜ê³  ì‚¬ìš©í•˜ê¸° í¸ë¦¬í•˜ì—¬ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤.",
                    "ì´ ìƒí’ˆì€ í’ˆì§ˆì´ í˜•í¸ì—†ê³  ì‚¬ìš©í•˜ê¸° ë¶ˆí¸í•´ì„œ ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                    0.3  # ë‚®ì€ ìœ ì‚¬ë„ ê¸°ëŒ€ (ë°˜ëŒ€ ì˜ë¯¸)
                ),
                (
                    "í”„ë¡œì íŠ¸ê°€ ì˜ˆì •ë³´ë‹¤ ë¹¨ë¦¬ ì™„ë£Œë˜ì–´ ëª¨ë“  íŒ€ì›ë“¤ì´ ë§Œì¡±í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    "í”„ë¡œì íŠ¸ê°€ ê³„íšë³´ë‹¤ ì§€ì—°ë˜ì–´ íŒ€ì›ë“¤ì´ ëª¨ë‘ ë¶ˆë§Œì„ í‘œí•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                    0.25
                ),
                (
                    "ìƒˆë¡œìš´ ì •ì±…ì´ ë„ì…ë˜ì–´ ì—…ë¬´ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "ìƒˆë¡œìš´ ê·œì • ë•Œë¬¸ì— ì—…ë¬´ ì²˜ë¦¬ê°€ ë”ìš± ë³µì¡í•´ì§€ê³  ë¹„íš¨ìœ¨ì ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    0.2
                )
            ],
            
            "ë¬¸ë§¥_ì˜ì¡´ì _ì˜ë¯¸": [
                (
                    "ì€í–‰ì—ì„œ ëˆì„ ì¸ì¶œí–ˆìŠµë‹ˆë‹¤.",
                    "ê°•ê°€ì—ì„œ ë‚šì‹œë¥¼ í–ˆìŠµë‹ˆë‹¤.",
                    0.1  # ë§¤ìš° ë‚®ì€ ìœ ì‚¬ë„ (ë™ìŒì´ì˜ì–´)
                ),
                (
                    "ì‚¬ê³¼ë¥¼ ë¨¹ì—ˆìŠµë‹ˆë‹¤.",
                    "ì‹¤ìˆ˜ì— ëŒ€í•´ ì‚¬ê³¼í–ˆìŠµë‹ˆë‹¤.",
                    0.15
                ),
                (
                    "ë°°ê°€ í•­êµ¬ì— ì •ë°•í–ˆìŠµë‹ˆë‹¤.",
                    "ë°°ê°€ ê³ íŒŒì„œ ìŒì‹ì„ ë¨¹ì—ˆìŠµë‹ˆë‹¤.",
                    0.1
                )
            ]
        }
        
        return scenarios
    
    def calculate_embedding_similarity(self, text1: str, text2: str, model: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì„ë² ë”© ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            embeddings = embedding_service.encode_texts([text1, text2], model)
            if embeddings is None or len(embeddings) < 2:
                return 0.0
            
            similarity = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]
            return float(similarity)
            
        except Exception as e:
            logger.error(f"Error calculating similarity for model {model}: {e}")
            return 0.0
    
    def test_scenario(self, scenario_name: str, test_cases: List[Tuple[str, str, float]]) -> Dict[str, Any]:
        """íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print(f"\n{'='*80}")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {scenario_name}")
        print(f"{'='*80}")
        
        results = {}
        
        for model in self.models:
            print(f"\nğŸ¤– ëª¨ë¸: {model}")
            print("-" * 60)
            
            model_results = {
                "similarities": [],
                "expected_similarities": [],
                "errors": [],
                "processing_times": []
            }
            
            for i, (text1, text2, expected_sim) in enumerate(test_cases, 1):
                start_time = time.time()
                
                try:
                    actual_sim = self.calculate_embedding_similarity(text1, text2, model)
                    processing_time = time.time() - start_time
                    
                    model_results["similarities"].append(actual_sim)
                    model_results["expected_similarities"].append(expected_sim)
                    model_results["processing_times"].append(processing_time)
                    
                    error = abs(actual_sim - expected_sim)
                    model_results["errors"].append(error)
                    
                    print(f"  í…ŒìŠ¤íŠ¸ {i}:")
                    print(f"    í…ìŠ¤íŠ¸1: {text1[:50]}...")
                    print(f"    í…ìŠ¤íŠ¸2: {text2[:50]}...")
                    print(f"    ì˜ˆìƒ ìœ ì‚¬ë„: {expected_sim:.3f}")
                    print(f"    ì‹¤ì œ ìœ ì‚¬ë„: {actual_sim:.3f}")
                    print(f"    ì˜¤ì°¨: {error:.3f}")
                    print(f"    ì²˜ë¦¬ ì‹œê°„: {processing_time:.3f}ì´ˆ")
                    print()
                    
                except Exception as e:
                    logger.error(f"Error in test case {i} for model {model}: {e}")
                    model_results["errors"].append(1.0)  # ìµœëŒ€ ì˜¤ì°¨ë¡œ ì²˜ë¦¬
            
            # ëª¨ë¸ë³„ í†µê³„ ê³„ì‚°
            if model_results["similarities"]:
                avg_error = np.mean(model_results["errors"])
                correlation = pearsonr(model_results["expected_similarities"], 
                                     model_results["similarities"])[0]
                spearman_corr = spearmanr(model_results["expected_similarities"], 
                                        model_results["similarities"])[0]
                avg_processing_time = np.mean(model_results["processing_times"])
                
                model_results.update({
                    "avg_error": avg_error,
                    "pearson_correlation": correlation,
                    "spearman_correlation": spearman_corr,
                    "avg_processing_time": avg_processing_time
                })
                
                print(f"ğŸ“Š {model} ì„±ëŠ¥ ìš”ì•½:")
                print(f"  í‰ê·  ì˜¤ì°¨: {avg_error:.3f}")
                print(f"  í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜: {correlation:.3f}")
                print(f"  ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜: {spearman_corr:.3f}")
                print(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_processing_time:.3f}ì´ˆ")
            
            results[model] = model_results
        
        return results

    def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        print("ğŸš€ ë³µì¡í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸ ìœ ì‚¬ë„ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸: {', '.join(self.models)}")
        print(f"ğŸ“Š ì´ {len(self.test_scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤, {sum(len(cases) for cases in self.test_scenarios.values())}ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤")

        all_results = {}
        overall_start_time = time.time()

        for scenario_name, test_cases in self.test_scenarios.items():
            scenario_results = self.test_scenario(scenario_name, test_cases)
            all_results[scenario_name] = scenario_results

        total_time = time.time() - overall_start_time

        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        self.analyze_overall_results(all_results, total_time)

        return all_results

    def analyze_overall_results(self, all_results: Dict[str, Any], total_time: float):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤."""
        print(f"\n{'='*80}")
        print("ğŸ“ˆ ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print(f"{'='*80}")

        model_summary = {}

        for model in self.models:
            all_errors = []
            all_correlations = []
            all_spearman_correlations = []
            all_processing_times = []

            for scenario_name, scenario_results in all_results.items():
                if model in scenario_results:
                    model_result = scenario_results[model]
                    if 'avg_error' in model_result:
                        all_errors.append(model_result['avg_error'])
                        all_correlations.append(model_result['pearson_correlation'])
                        all_spearman_correlations.append(model_result['spearman_correlation'])
                        all_processing_times.extend(model_result['processing_times'])

            if all_errors:
                model_summary[model] = {
                    "overall_avg_error": np.mean(all_errors),
                    "overall_pearson_correlation": np.mean(all_correlations),
                    "overall_spearman_correlation": np.mean(all_spearman_correlations),
                    "overall_avg_processing_time": np.mean(all_processing_times),
                    "total_processing_time": np.sum(all_processing_times),
                    "scenario_count": len(all_errors)
                }

        # ê²°ê³¼ ì¶œë ¥
        print(f"â±ï¸  ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print()

        for model, summary in model_summary.items():
            print(f"ğŸ¤– {model}:")
            print(f"  ì „ì²´ í‰ê·  ì˜¤ì°¨: {summary['overall_avg_error']:.3f}")
            print(f"  ì „ì²´ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜: {summary['overall_pearson_correlation']:.3f}")
            print(f"  ì „ì²´ ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜: {summary['overall_spearman_correlation']:.3f}")
            print(f"  í‰ê·  ì²˜ë¦¬ ì‹œê°„: {summary['overall_avg_processing_time']:.3f}ì´ˆ")
            print(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {summary['total_processing_time']:.2f}ì´ˆ")
            print()

        # ëª¨ë¸ ë¹„êµ
        if len(model_summary) > 1:
            print("ğŸ† ëª¨ë¸ ë¹„êµ ê²°ê³¼:")

            # ê°€ì¥ ë‚®ì€ ì˜¤ì°¨ë¥¼ ê°€ì§„ ëª¨ë¸
            best_accuracy_model = min(model_summary.keys(),
                                    key=lambda m: model_summary[m]['overall_avg_error'])
            print(f"  ê°€ì¥ ì •í™•í•œ ëª¨ë¸ (ë‚®ì€ ì˜¤ì°¨): {best_accuracy_model}")

            # ê°€ì¥ ë†’ì€ ìƒê´€ê³„ìˆ˜ë¥¼ ê°€ì§„ ëª¨ë¸
            best_correlation_model = max(model_summary.keys(),
                                       key=lambda m: model_summary[m]['overall_pearson_correlation'])
            print(f"  ê°€ì¥ ì¼ê´€ëœ ëª¨ë¸ (ë†’ì€ ìƒê´€ê³„ìˆ˜): {best_correlation_model}")

            # ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸
            fastest_model = min(model_summary.keys(),
                              key=lambda m: model_summary[m]['overall_avg_processing_time'])
            print(f"  ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸: {fastest_model}")

        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥ ë¶„ì„
        print("\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥ ë¶„ì„:")
        for scenario_name, scenario_results in all_results.items():
            print(f"\n  {scenario_name}:")
            for model in self.models:
                if model in scenario_results and 'avg_error' in scenario_results[model]:
                    result = scenario_results[model]
                    print(f"    {model}: ì˜¤ì°¨ {result['avg_error']:.3f}, "
                          f"ìƒê´€ê³„ìˆ˜ {result['pearson_correlation']:.3f}")

    def save_results_to_file(self, results: Dict[str, Any], filename: str = "embedding_similarity_test_results.json"):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            serializable_results = {}
            for scenario, scenario_data in results.items():
                serializable_results[scenario] = {}
                for model, model_data in scenario_data.items():
                    serializable_results[scenario][model] = {}
                    for key, value in model_data.items():
                        if isinstance(value, np.ndarray):
                            serializable_results[scenario][model][key] = value.tolist()
                        elif isinstance(value, (np.float64, np.float32)):
                            serializable_results[scenario][model][key] = float(value)
                        else:
                            serializable_results[scenario][model][key] = value

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(serializable_results, f, ensure_ascii=False, indent=2)

            print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” í™•ì¸
        print("ğŸ”§ ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        available_models = embedding_service.get_available_models()
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {[model['id'] for model in available_models]}")

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_runner = ComplexEmbeddingSimilarityTest()
        results = test_runner.run_all_tests()

        # ê²°ê³¼ ì €ì¥
        test_runner.save_results_to_file(results)

        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()
