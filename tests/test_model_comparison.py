"""
ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸: ìƒˆë¡œìš´ Arctic ëª¨ë¸ê³¼ ê¸°ì¡´ ëª¨ë¸ë“¤ ë¹„êµ
"""

import time
import requests
import json
from typing import List, Dict

# í…ŒìŠ¤íŠ¸ ì„¤ì •
BASE_URL = "http://localhost:8000"
API_KEY = "sk-kure-v1-test-key-12345"
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

class ModelComparisonTest:
    def __init__(self):
        self.base_url = BASE_URL
        self.headers = HEADERS
        self.test_texts = [
            "ì•ˆë…•í•˜ì„¸ìš”",
            "í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬",
            "ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹",
            "ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
            "ë²¡í„° ì„ë² ë”© ê¸°ìˆ ",
            "RAG ì‹œìŠ¤í…œ êµ¬í˜„",
            "MCP í”„ë¡œí† ì½œ ì§€ì›",
            "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„"
        ]
        self.models = [
            "dragonkue/snowflake-arctic-embed-l-v2.0-ko",
            "nlpai-lab/KURE-v1",
            "nlpai-lab/KoE5"
        ]
        
    def test_embedding_performance(self, model: str, texts: List[str]) -> Dict:
        """íŠ¹ì • ëª¨ë¸ì˜ ì„ë² ë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        
        try:
            payload = {
                "input": texts,
                "model": model
            }
            
            response = requests.post(f"{self.base_url}/embeddings", 
                                   headers=self.headers, json=payload)
            
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                embeddings = data.get("data", [])
                
                if embeddings:
                    embedding_dim = len(embeddings[0]["embedding"])
                    throughput = len(texts) / duration
                    
                    return {
                        "success": True,
                        "model": model,
                        "duration": duration,
                        "throughput": throughput,
                        "embedding_dim": embedding_dim,
                        "num_texts": len(texts),
                        "avg_time_per_text": duration / len(texts)
                    }
                else:
                    return {"success": False, "error": "No embeddings returned"}
            else:
                return {"success": False, "error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            duration = time.time() - start_time
            return {"success": False, "error": str(e), "duration": duration}
    
    def test_embedding_quality(self, model: str) -> Dict:
        """ì„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (ìœ ì‚¬ë„ ê³„ì‚°)"""
        try:
            # ìœ ì‚¬í•œ ì˜ë¯¸ì˜ í…ìŠ¤íŠ¸ ìŒ
            similar_pairs = [
                ("ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•"),
                ("ì¸ê³µì§€ëŠ¥", "AI"),
                ("ë¨¸ì‹ ëŸ¬ë‹", "ê¸°ê³„í•™ìŠµ"),
                ("ë¬¸ì„œ ê²€ìƒ‰", "ë¬¸ì„œ ì°¾ê¸°")
            ]
            
            # ë‹¤ë¥¸ ì˜ë¯¸ì˜ í…ìŠ¤íŠ¸ ìŒ
            different_pairs = [
                ("ì•ˆë…•í•˜ì„¸ìš”", "ì»´í“¨í„°"),
                ("ì¸ê³µì§€ëŠ¥", "ìŒì‹"),
                ("ê²€ìƒ‰", "ìš´ë™"),
                ("ê¸°ìˆ ", "ë‚ ì”¨")
            ]
            
            similar_scores = []
            different_scores = []
            
            # ìœ ì‚¬í•œ ìŒë“¤ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            for text1, text2 in similar_pairs:
                payload = {
                    "text1": text1,
                    "text2": text2,
                    "model": model
                }
                
                response = requests.post(f"{self.base_url}/similarity", 
                                       headers=self.headers, json=payload)
                
                if response.status_code == 200:
                    data = response.json()
                    similar_scores.append(data.get("similarity", 0))
            
            # ë‹¤ë¥¸ ìŒë“¤ì˜ ìœ ì‚¬ë„ ê³„ì‚°
            for text1, text2 in different_pairs:
                payload = {
                    "text1": text1,
                    "text2": text2,
                    "model": model
                }
                
                response = requests.post(f"{self.base_url}/similarity", 
                                       headers=self.headers, json=payload)
                
                if response.status_code == 200:
                    data = response.json()
                    different_scores.append(data.get("similarity", 0))
            
            if similar_scores and different_scores:
                avg_similar = sum(similar_scores) / len(similar_scores)
                avg_different = sum(different_scores) / len(different_scores)
                discrimination = avg_similar - avg_different
                
                return {
                    "success": True,
                    "model": model,
                    "avg_similar_score": avg_similar,
                    "avg_different_score": avg_different,
                    "discrimination": discrimination,
                    "similar_scores": similar_scores,
                    "different_scores": different_scores
                }
            else:
                return {"success": False, "error": "Failed to calculate similarities"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def run_comparison(self):
        """ëª¨ë“  ëª¨ë¸ ë¹„êµ ì‹¤í–‰"""
        print("ğŸ” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 70)
        
        performance_results = []
        quality_results = []
        
        for model in self.models:
            print(f"\nğŸ“Š {model} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            perf_result = self.test_embedding_performance(model, self.test_texts)
            performance_results.append(perf_result)
            
            if perf_result["success"]:
                print(f"  â±ï¸  ì²˜ë¦¬ ì‹œê°„: {perf_result['duration']:.3f}ì´ˆ")
                print(f"  ğŸš€ ì²˜ë¦¬ëŸ‰: {perf_result['throughput']:.2f} texts/sec")
                print(f"  ğŸ“ ì„ë² ë”© ì°¨ì›: {perf_result['embedding_dim']}")
                print(f"  âš¡ í…ìŠ¤íŠ¸ë‹¹ í‰ê·  ì‹œê°„: {perf_result['avg_time_per_text']:.3f}ì´ˆ")
            else:
                print(f"  âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {perf_result.get('error')}")
            
            # í’ˆì§ˆ í…ŒìŠ¤íŠ¸
            quality_result = self.test_embedding_quality(model)
            quality_results.append(quality_result)
            
            if quality_result["success"]:
                print(f"  ğŸ¯ ìœ ì‚¬ í…ìŠ¤íŠ¸ í‰ê·  ì ìˆ˜: {quality_result['avg_similar_score']:.3f}")
                print(f"  ğŸ¯ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í‰ê·  ì ìˆ˜: {quality_result['avg_different_score']:.3f}")
                print(f"  ğŸ“ˆ íŒë³„ë ¥: {quality_result['discrimination']:.3f}")
            else:
                print(f"  âŒ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {quality_result.get('error')}")
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 70)
        print("ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½")
        print("=" * 70)
        
        successful_perf = [r for r in performance_results if r["success"]]
        if successful_perf:
            print("\nğŸš€ ì²˜ë¦¬ ì„±ëŠ¥ ìˆœìœ„:")
            sorted_perf = sorted(successful_perf, key=lambda x: x["throughput"], reverse=True)
            for i, result in enumerate(sorted_perf, 1):
                print(f"  {i}. {result['model']}")
                print(f"     ì²˜ë¦¬ëŸ‰: {result['throughput']:.2f} texts/sec")
                print(f"     ì²˜ë¦¬ ì‹œê°„: {result['duration']:.3f}ì´ˆ")
        
        successful_quality = [r for r in quality_results if r["success"]]
        if successful_quality:
            print("\nğŸ¯ ì„ë² ë”© í’ˆì§ˆ ìˆœìœ„:")
            sorted_quality = sorted(successful_quality, key=lambda x: x["discrimination"], reverse=True)
            for i, result in enumerate(sorted_quality, 1):
                print(f"  {i}. {result['model']}")
                print(f"     íŒë³„ë ¥: {result['discrimination']:.3f}")
                print(f"     ìœ ì‚¬ í…ìŠ¤íŠ¸ ì ìˆ˜: {result['avg_similar_score']:.3f}")
                print(f"     ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì ìˆ˜: {result['avg_different_score']:.3f}")
        
        # ì¶”ì²œ ëª¨ë¸
        if successful_perf and successful_quality:
            best_perf_model = sorted_perf[0]["model"]
            best_quality_model = sorted_quality[0]["model"]
            
            print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_perf_model}")
            print(f"ğŸ¯ ìµœê³  í’ˆì§ˆ ëª¨ë¸: {best_quality_model}")
            
            if best_perf_model == best_quality_model:
                print(f"ğŸŒŸ ì¢…í•© ì¶”ì²œ ëª¨ë¸: {best_perf_model}")
            else:
                print("âš–ï¸  ì„±ëŠ¥ê³¼ í’ˆì§ˆ ê°„ íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ìˆìŠµë‹ˆë‹¤.")
        
        print("\nâœ… ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return performance_results, quality_results

if __name__ == "__main__":
    tester = ModelComparisonTest()
    tester.run_comparison()
