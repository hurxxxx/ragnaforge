"""
ì„±ëŠ¥ ë° ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸: Ragnaforge ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
ë™ì‹œ ìš”ì²­, ëŒ€ìš©ëŸ‰ íŒŒì¼, ì—°ì† ì²˜ë¦¬ ë“±ì„ í…ŒìŠ¤íŠ¸
"""

import asyncio
import concurrent.futures
import json
import os
import time
import requests
from pathlib import Path
import threading

# í…ŒìŠ¤íŠ¸ ì„¤ì •
BASE_URL = "http://localhost:8000"
API_KEY = "sk-kure-v1-test-key-12345"
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

class PerformanceStressTest:
    def __init__(self):
        self.base_url = BASE_URL
        self.headers = HEADERS
        self.results = []
        
    def log_result(self, test_name, success, duration, details=None):
        """ê²°ê³¼ ë¡œê¹…"""
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name} ({duration:.2f}s)")
        if details:
            print(f"    {details}")
        
        self.results.append({
            "test": test_name,
            "success": success,
            "duration": duration,
            "details": details
        })
    
    def test_concurrent_embeddings(self, num_requests=10):
        """ë™ì‹œ ì„ë² ë”© ìš”ì²­ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ”„ ë™ì‹œ ì„ë² ë”© ìš”ì²­ í…ŒìŠ¤íŠ¸ ({num_requests}ê°œ ìš”ì²­)")
        
        def make_embedding_request(request_id):
            start_time = time.time()
            try:
                payload = {
                    "input": [f"ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ {request_id}"],
                    "model": "nlpai-lab/KURE-v1"
                }
                response = requests.post(f"{self.base_url}/embeddings", 
                                       headers=self.headers, json=payload)
                duration = time.time() - start_time
                return {
                    "request_id": request_id,
                    "success": response.status_code == 200,
                    "duration": duration,
                    "status_code": response.status_code
                }
            except Exception as e:
                duration = time.time() - start_time
                return {
                    "request_id": request_id,
                    "success": False,
                    "duration": duration,
                    "error": str(e)
                }
        
        start_time = time.time()
        
        # ë™ì‹œ ìš”ì²­ ì‹¤í–‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=num_requests) as executor:
            futures = [executor.submit(make_embedding_request, i) for i in range(num_requests)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        total_duration = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        avg_duration = sum(r["duration"] for r in successful_requests) / len(successful_requests) if successful_requests else 0
        max_duration = max(r["duration"] for r in successful_requests) if successful_requests else 0
        min_duration = min(r["duration"] for r in successful_requests) if successful_requests else 0
        
        details = f"ì„±ê³µ: {len(successful_requests)}/{num_requests}, í‰ê· : {avg_duration:.2f}s, ìµœëŒ€: {max_duration:.2f}s, ìµœì†Œ: {min_duration:.2f}s"
        
        self.log_result("Concurrent Embeddings", len(failed_requests) == 0, total_duration, details)
        return len(failed_requests) == 0
    
    def test_large_text_embedding(self):
        """ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“„ ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ ì„ë² ë”© í…ŒìŠ¤íŠ¸")
        
        # ê¸´ í…ìŠ¤íŠ¸ ìƒì„± (ì•½ 4000ì)
        large_text = "í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ëŠ” ë§¤ìš° ì¤‘ìš”í•œ ê¸°ìˆ ì…ë‹ˆë‹¤. " * 200
        
        start_time = time.time()
        try:
            payload = {
                "input": [large_text],
                "model": "nlpai-lab/KURE-v1"
            }
            response = requests.post(f"{self.base_url}/embeddings", 
                                   headers=self.headers, json=payload)
            duration = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                embedding_dim = len(data["data"][0]["embedding"])
                details = f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(large_text)}, ì„ë² ë”© ì°¨ì›: {embedding_dim}"
                self.log_result("Large Text Embedding", True, duration, details)
                return True
            else:
                self.log_result("Large Text Embedding", False, duration, f"HTTP {response.status_code}")
                return False
        except Exception as e:
            duration = time.time() - start_time
            self.log_result("Large Text Embedding", False, duration, f"Error: {str(e)}")
            return False
    
    def test_batch_embedding_performance(self):
        """ë°°ì¹˜ ì„ë² ë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“¦ ë°°ì¹˜ ì„ë² ë”© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸° í…ŒìŠ¤íŠ¸
        batch_sizes = [1, 5, 10, 16]
        results = []
        
        for batch_size in batch_sizes:
            texts = [f"ë°°ì¹˜ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ {i}" for i in range(batch_size)]
            
            start_time = time.time()
            try:
                payload = {
                    "input": texts,
                    "model": "nlpai-lab/KURE-v1"
                }
                response = requests.post(f"{self.base_url}/embeddings", 
                                       headers=self.headers, json=payload)
                duration = time.time() - start_time
                
                if response.status_code == 200:
                    throughput = batch_size / duration
                    results.append({
                        "batch_size": batch_size,
                        "duration": duration,
                        "throughput": throughput,
                        "success": True
                    })
                    print(f"    ë°°ì¹˜ í¬ê¸° {batch_size}: {duration:.2f}s, ì²˜ë¦¬ëŸ‰: {throughput:.2f} texts/sec")
                else:
                    results.append({
                        "batch_size": batch_size,
                        "duration": duration,
                        "success": False,
                        "status_code": response.status_code
                    })
            except Exception as e:
                duration = time.time() - start_time
                results.append({
                    "batch_size": batch_size,
                    "duration": duration,
                    "success": False,
                    "error": str(e)
                })
        
        successful_results = [r for r in results if r["success"]]
        if successful_results:
            best_throughput = max(r["throughput"] for r in successful_results)
            best_batch = next(r for r in successful_results if r["throughput"] == best_throughput)
            details = f"ìµœì  ë°°ì¹˜ í¬ê¸°: {best_batch['batch_size']}, ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {best_throughput:.2f} texts/sec"
            self.log_result("Batch Embedding Performance", True, 0, details)
            return True
        else:
            self.log_result("Batch Embedding Performance", False, 0, "ëª¨ë“  ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return False
    
    def test_search_performance(self):
        """ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ” ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        search_queries = [
            "MCP ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰",
            "AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ",
            "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤",
            "ë¬¸ì„œ ë³€í™˜ ì²˜ë¦¬",
            "í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬"
        ]
        
        results = []
        
        for i, query in enumerate(search_queries):
            start_time = time.time()
            try:
                payload = {
                    "query": query,
                    "top_k": 5,
                    "search_type": "vector"
                }
                response = requests.post(f"{self.base_url}/v1/search", 
                                       headers=self.headers, json=payload)
                duration = time.time() - start_time
                
                if response.status_code == 200:
                    data = response.json()
                    result_count = len(data.get("results", []))
                    results.append({
                        "query": query,
                        "duration": duration,
                        "result_count": result_count,
                        "success": True
                    })
                    print(f"    ì¿¼ë¦¬ {i+1}: {duration:.2f}s, ê²°ê³¼: {result_count}ê°œ")
                else:
                    results.append({
                        "query": query,
                        "duration": duration,
                        "success": False,
                        "status_code": response.status_code
                    })
            except Exception as e:
                duration = time.time() - start_time
                results.append({
                    "query": query,
                    "duration": duration,
                    "success": False,
                    "error": str(e)
                })
        
        successful_results = [r for r in results if r["success"]]
        if successful_results:
            avg_duration = sum(r["duration"] for r in successful_results) / len(successful_results)
            total_results = sum(r["result_count"] for r in successful_results)
            details = f"í‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_duration:.2f}s, ì´ ê²°ê³¼: {total_results}ê°œ"
            self.log_result("Search Performance", True, avg_duration, details)
            return True
        else:
            self.log_result("Search Performance", False, 0, "ëª¨ë“  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return False
    
    def test_storage_operations_performance(self):
        """Storage ì‘ì—… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\nğŸ“ Storage ì‘ì—… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        operations = [
            ("stats", lambda: requests.get(f"{self.base_url}/v1/storage/stats", headers=self.headers)),
            ("list_uploads", lambda: requests.get(f"{self.base_url}/v1/storage/files/uploads", headers=self.headers)),
            ("list_processed", lambda: requests.get(f"{self.base_url}/v1/storage/files/processed", headers=self.headers)),
            ("cleanup", lambda: requests.post(f"{self.base_url}/v1/storage/cleanup", headers=self.headers, json={"max_age_hours": 24}))
        ]
        
        results = []
        
        for op_name, op_func in operations:
            start_time = time.time()
            try:
                response = op_func()
                duration = time.time() - start_time
                
                if response.status_code == 200:
                    results.append({
                        "operation": op_name,
                        "duration": duration,
                        "success": True
                    })
                    print(f"    {op_name}: {duration:.3f}s")
                else:
                    results.append({
                        "operation": op_name,
                        "duration": duration,
                        "success": False,
                        "status_code": response.status_code
                    })
            except Exception as e:
                duration = time.time() - start_time
                results.append({
                    "operation": op_name,
                    "duration": duration,
                    "success": False,
                    "error": str(e)
                })
        
        successful_results = [r for r in results if r["success"]]
        if successful_results:
            avg_duration = sum(r["duration"] for r in successful_results) / len(successful_results)
            details = f"ì„±ê³µí•œ ì‘ì—…: {len(successful_results)}/{len(operations)}, í‰ê·  ì‹œê°„: {avg_duration:.3f}s"
            self.log_result("Storage Operations Performance", len(successful_results) == len(operations), avg_duration, details)
            return len(successful_results) == len(operations)
        else:
            self.log_result("Storage Operations Performance", False, 0, "ëª¨ë“  Storage ì‘ì—… ì‹¤íŒ¨")
            return False
    
    def run_all_tests(self):
        """ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ Ragnaforge ì„±ëŠ¥ ë° ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 70)
        
        total_start_time = time.time()
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        tests = [
            lambda: self.test_concurrent_embeddings(10),
            self.test_large_text_embedding,
            self.test_batch_embedding_performance,
            self.test_search_performance,
            self.test_storage_operations_performance
        ]
        
        passed = 0
        failed = 0
        
        for test in tests:
            if test():
                passed += 1
            else:
                failed += 1
        
        total_duration = time.time() - total_start_time
        
        print("\n" + "=" * 70)
        print(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print(f"âœ… í†µê³¼: {passed}")
        print(f"âŒ ì‹¤íŒ¨: {failed}")
        print(f"â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_duration:.2f}ì´ˆ")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {(passed/(passed+failed)*100):.1f}%")
        
        if failed == 0:
            print("\nğŸ‰ ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        else:
            print(f"\nâš ï¸  {failed}ê°œì˜ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        return failed == 0

if __name__ == "__main__":
    test_runner = PerformanceStressTest()
    success = test_runner.run_all_tests()
    exit(0 if success else 1)
