"""
KURE ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ - Streamlit UI
ì¢…í•©ì ì¸ ë¬¸ì„œ ê´€ë¦¬, ê²€ìƒ‰, ì±—ë´‡ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë°ëª¨ ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
import requests
import json
import time
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any
import plotly.express as px
import plotly.graph_objects as go

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="KURE Search System",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì „ì—­ ì„¤ì •
API_BASE_URL = "http://localhost:8000"
DEFAULT_API_KEY = "sk-kure-v1-test-key-12345"

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-card {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .status-healthy {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .status-error {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
    }
    .search-result {
        border: 1px solid #dee2e6;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 0.5rem 0;
        background-color: #f8f9fa;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    .assistant-message {
        background-color: #f3e5f5;
        border-left: 4px solid #9c27b0;
    }
</style>
""", unsafe_allow_html=True)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def make_api_request(endpoint: str, method: str = "GET", data: Dict = None, files: Dict = None) -> Dict:
    """API ìš”ì²­ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜"""
    try:
        headers = {"Authorization": f"Bearer {st.session_state.get('api_key', DEFAULT_API_KEY)}"}
        url = f"{API_BASE_URL}{endpoint}"
        
        if method == "GET":
            response = requests.get(url, headers=headers, params=data)
        elif method == "POST":
            if files:
                response = requests.post(url, headers=headers, data=data, files=files)
            else:
                headers["Content-Type"] = "application/json"
                response = requests.post(url, headers=headers, json=data)
        
        return {
            "success": response.status_code == 200,
            "data": response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text,
            "status_code": response.status_code
        }
    except Exception as e:
        return {"success": False, "error": str(e), "status_code": 500}

def check_system_health() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
    health_checks = {}
    
    # ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬
    result = make_api_request("/health")
    health_checks["api"] = {
        "status": "healthy" if result["success"] else "error",
        "details": result.get("data", {})
    }
    
    # ë²¡í„° DB ìƒíƒœ (Qdrant)
    result = make_api_request("/v1/storage/stats")
    health_checks["vector_db"] = {
        "status": "healthy" if result["success"] else "error",
        "details": result.get("data", {})
    }
    
    # ë¦¬ë­í¬ ì„œë¹„ìŠ¤ ìƒíƒœ
    result = make_api_request("/v1/rerank/health")
    health_checks["rerank"] = {
        "status": "healthy" if result["success"] else "error",
        "details": result.get("data", {})
    }
    
    return health_checks

def format_file_size(size_bytes: int) -> str:
    """íŒŒì¼ í¬ê¸°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜"""
    if size_bytes == 0:
        return "0 B"
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    return f"{size_bytes:.1f} {size_names[i]}"

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'api_key' not in st.session_state:
    st.session_state.api_key = DEFAULT_API_KEY
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'search_results' not in st.session_state:
    st.session_state.search_results = []

# ë©”ì¸ í—¤ë”
st.markdown('<div class="main-header">ğŸ” KURE ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” - ì„¤ì • ë° ìƒíƒœ
with st.sidebar:
    st.header("âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì •")
    
    # API í‚¤ ì„¤ì •
    api_key = st.text_input("API Key", value=st.session_state.api_key, type="password")
    st.session_state.api_key = api_key
    
    st.divider()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
    
    if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        with st.spinner("ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘..."):
            st.session_state.health_status = check_system_health()
    
    if 'health_status' not in st.session_state:
        st.session_state.health_status = check_system_health()
    
    # ìƒíƒœ í‘œì‹œ
    for service, status in st.session_state.health_status.items():
        status_class = "status-healthy" if status["status"] == "healthy" else "status-error"
        status_icon = "âœ…" if status["status"] == "healthy" else "âŒ"
        
        service_names = {
            "api": "API ì„œë²„",
            "vector_db": "ë²¡í„° DB",
            "rerank": "ë¦¬ë­í¬ ì„œë¹„ìŠ¤"
        }
        
        st.markdown(f"""
        <div class="status-card {status_class}">
            {status_icon} <strong>{service_names.get(service, service)}</strong><br>
            ìƒíƒœ: {status["status"]}
        </div>
        """, unsafe_allow_html=True)

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“„ ë¬¸ì„œ ê´€ë¦¬", 
    "ğŸ” ê²€ìƒ‰", 
    "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼", 
    "ğŸ¤– AI ì±—ë´‡",
    "ğŸ“ˆ ì‹œìŠ¤í…œ í†µê³„"
])

# íƒ­ 1: ë¬¸ì„œ ê´€ë¦¬
with tab1:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['pdf'],
            help="PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤"
        )
        
        if uploaded_file:
            st.info(f"ì„ íƒëœ íŒŒì¼: {uploaded_file.name} ({format_file_size(uploaded_file.size)})")
            
            # ì²˜ë¦¬ ì˜µì…˜
            st.subheader("ì²˜ë¦¬ ì˜µì…˜")
            col_opt1, col_opt2 = st.columns(2)
            
            with col_opt1:
                conversion_method = st.selectbox("ë³€í™˜ ë°©ë²•", ["marker", "docling"], index=0)
                chunk_strategy = st.selectbox("ì²­í‚¹ ì „ëµ", ["recursive", "semantic"], index=0)
            
            with col_opt2:
                chunk_size = st.number_input("ì²­í¬ í¬ê¸°", min_value=100, max_value=1000, value=380)
                overlap = st.number_input("ì˜¤ë²„ë©", min_value=0, max_value=200, value=70)
            
            generate_embeddings = st.checkbox("ì„ë² ë”© ìƒì„±", value=True, key="upload_embeddings")
            embedding_model = st.selectbox("ì„ë² ë”© ëª¨ë¸", ["nlpai-lab/KURE-v1"], index=0)
            
            if st.button("ğŸ“¤ ì—…ë¡œë“œ ë° ì²˜ë¦¬", use_container_width=True):
                with st.spinner("íŒŒì¼ ì—…ë¡œë“œ ì¤‘..."):
                    # íŒŒì¼ ì—…ë¡œë“œ
                    files = {"file": (uploaded_file.name, uploaded_file.getvalue(), "application/pdf")}
                    upload_result = make_api_request("/v1/upload", "POST", files=files)
                    
                    if upload_result["success"]:
                        file_id = upload_result["data"].get("file_id")
                        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ! ID: {file_id}")
                        
                        # ë¬¸ì„œ ì²˜ë¦¬
                        with st.spinner("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘..."):
                            process_data = {
                                "file_id": file_id,
                                "conversion_method": conversion_method,
                                "extract_images": False,
                                "chunk_strategy": chunk_strategy,
                                "chunk_size": chunk_size,
                                "overlap": overlap,
                                "generate_embeddings": generate_embeddings,
                                "embedding_model": embedding_model
                            }
                            
                            process_result = make_api_request("/v1/process", "POST", process_data)
                            
                            if process_result["success"]:
                                st.success("âœ… ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
                                st.json(process_result["data"])
                            else:
                                st.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {process_result.get('error', 'Unknown error')}")
                    else:
                        st.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get('error', 'Unknown error')}")
    
    with col2:
        st.header("ğŸ“‹ ë¬¸ì„œ ëª©ë¡")
        
        if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            with st.spinner("ë¬¸ì„œ ëª©ë¡ ë¡œë”© ì¤‘..."):
                files_result = make_api_request("/v1/files", "GET", {"page_size": 50})

                if files_result["success"]:
                    files_data = files_result["data"]
                    files_list = files_data.get("files", [])

                    # ê° ë¬¸ì„œì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì²˜ë¦¬ëœ ë¬¸ì„œë§Œ)
                    for file_info in files_list:
                        if file_info.get("is_processed") and file_info.get("document_id"):
                            doc_id = file_info["document_id"]
                            # ë¬¸ì„œ ì²­í¬ ìˆ˜ ì¡°íšŒ ì‹œë„
                            try:
                                # ê°„ë‹¨í•œ ê²€ìƒ‰ìœ¼ë¡œ í•´ë‹¹ ë¬¸ì„œì˜ ì²­í¬ ìˆ˜ í™•ì¸
                                search_result = make_api_request("/v1/search/vector", "POST", {
                                    "query": "test",
                                    "limit": 1,
                                    "score_threshold": 0.0,
                                    "filters": {"document_id": doc_id}
                                })
                                if search_result["success"]:
                                    file_info["chunk_count"] = search_result["data"].get("total_results", 0)
                                    file_info["has_embeddings"] = file_info["chunk_count"] > 0
                            except:
                                file_info["chunk_count"] = 0
                                file_info["has_embeddings"] = False

                    st.session_state.files_list = files_list
                else:
                    st.error("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if 'files_list' in st.session_state and st.session_state.files_list:
            st.write(f"ì´ {len(st.session_state.files_list)}ê°œì˜ ë¬¸ì„œ")
            
            # ë¬¸ì„œ ëª©ë¡ í‘œì‹œ
            for file_info in st.session_state.files_list[:10]:  # ìµœê·¼ 10ê°œë§Œ í‘œì‹œ
                with st.expander(f"ğŸ“„ {file_info.get('filename', 'Unknown')}"):
                    col_info1, col_info2 = st.columns(2)

                    with col_info1:
                        st.write(f"**íŒŒì¼ ID:** {file_info.get('file_id', file_info.get('id', 'N/A'))}")
                        st.write(f"**í¬ê¸°:** {format_file_size(file_info.get('file_size', file_info.get('size', 0)))}")
                        st.write(f"**íƒ€ì…:** {file_info.get('file_type', 'N/A')}")

                    with col_info2:
                        created_at = file_info.get('created_at', 0)
                        if created_at:
                            upload_time = datetime.fromtimestamp(created_at).strftime("%Y-%m-%d %H:%M:%S")
                        else:
                            upload_time = 'N/A'
                        st.write(f"**ì—…ë¡œë“œ:** {upload_time}")
                        st.write(f"**ì²˜ë¦¬ ìƒíƒœ:** {'âœ… ì™„ë£Œ' if file_info.get('is_processed') else 'âŒ ë¯¸ì²˜ë¦¬'}")
                        st.write(f"**ì¤‘ë³µ íŒŒì¼:** {'âš ï¸ ì¤‘ë³µ' if file_info.get('is_duplicate') else 'âœ… ì›ë³¸'}")

                        # ì²­í¬ ìˆ˜ì™€ ì„ë² ë”© ì •ë³´
                        chunk_count = file_info.get('chunk_count', 0)
                        has_embeddings = file_info.get('has_embeddings', False)
                        st.write(f"**ì²­í¬ ìˆ˜:** {chunk_count}")
                        st.write(f"**ì„ë² ë”©:** {'âœ…' if has_embeddings else 'âŒ'}")

                        # ë¬¸ì„œ IDê°€ ìˆìœ¼ë©´ í‘œì‹œ
                        document_id = file_info.get('document_id')
                        if document_id:
                            st.write(f"**ë¬¸ì„œ ID:** {document_id[:8]}...")
        else:
            st.info("ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ë ¤ë©´ 'ëª©ë¡ ìƒˆë¡œê³ ì¹¨' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# íƒ­ 2: ê²€ìƒ‰
with tab2:
    st.header("ğŸ” ë¬¸ì„œ ê²€ìƒ‰")
    
    # ê²€ìƒ‰ ì„¤ì •
    col_search1, col_search2 = st.columns([2, 1])
    
    with col_search1:
        query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬")
    
    with col_search2:
        search_type = st.selectbox("ê²€ìƒ‰ íƒ€ì…", ["hybrid", "vector", "text"])
    
    # ê³ ê¸‰ ì„¤ì •
    with st.expander("ğŸ”§ ê³ ê¸‰ ê²€ìƒ‰ ì„¤ì •"):
        col_adv1, col_adv2, col_adv3 = st.columns(3)
        
        with col_adv1:
            limit = st.number_input("ê²°ê³¼ ìˆ˜", min_value=1, max_value=50, value=10)
            score_threshold = st.number_input("ì ìˆ˜ ì„ê³„ê°’", min_value=0.0, max_value=1.0, value=0.3, step=0.1)
        
        with col_adv2:
            if search_type == "hybrid":
                vector_weight = st.slider("ë²¡í„° ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.7)
                text_weight = 1.0 - vector_weight
                st.write(f"í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜: {text_weight:.1f}")
        
        with col_adv3:
            rerank = st.checkbox("ë¦¬ë­í‚¹ ì ìš©", value=True, key="search_rerank")
            if rerank:
                rerank_top_k = st.number_input("ë¦¬ë­í¬ ëŒ€ìƒ ìˆ˜", min_value=5, max_value=100, value=20)
    
    # ê²€ìƒ‰ ì‹¤í–‰
    if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", use_container_width=True) and query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            search_data = {
                "query": query,
                "limit": limit
            }
            
            if search_type == "vector":
                search_data.update({
                    "score_threshold": score_threshold,
                    "embedding_model": "nlpai-lab/KURE-v1"
                })
                if rerank:
                    search_data.update({
                        "rerank": True,
                        "rerank_top_k": rerank_top_k
                    })
            elif search_type == "text":
                search_data["highlight"] = True
            elif search_type == "hybrid":
                search_data.update({
                    "vector_weight": vector_weight,
                    "text_weight": text_weight,
                    "embedding_model": "nlpai-lab/KURE-v1"
                })
                if rerank:
                    search_data.update({
                        "rerank": True,
                        "rerank_top_k": rerank_top_k
                    })
            
            search_result = make_api_request(f"/v1/search/{search_type}", "POST", search_data)
            
            if search_result["success"]:
                st.session_state.search_results = search_result["data"]
                st.session_state.last_query = query
                st.success(f"âœ… ê²€ìƒ‰ ì™„ë£Œ! {len(search_result['data'].get('results', []))}ê°œ ê²°ê³¼ ë°œê²¬")
                
                # ê²€ìƒ‰ í†µê³„
                search_time = search_result["data"].get("search_time", 0)
                st.info(f"â±ï¸ ê²€ìƒ‰ ì‹œê°„: {search_time:.3f}ì´ˆ")
            else:
                st.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {search_result.get('error', 'Unknown error')}")

# íƒ­ 3: ê²€ìƒ‰ ê²°ê³¼
with tab3:
    st.header("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
    
    if st.session_state.search_results:
        results = st.session_state.search_results.get("results", [])
        
        if results:
            # ê²°ê³¼ í†µê³„
            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
            
            with col_stat1:
                st.metric("ì´ ê²°ê³¼ ìˆ˜", len(results))
            
            with col_stat2:
                avg_score = sum(r.get("score", 0) for r in results) / len(results)
                st.metric("í‰ê·  ì ìˆ˜", f"{avg_score:.3f}")
            
            with col_stat3:
                search_time = st.session_state.search_results.get("search_time", 0)
                st.metric("ê²€ìƒ‰ ì‹œê°„", f"{search_time:.3f}ì´ˆ")
            
            with col_stat4:
                search_type = st.session_state.search_results.get("search_type", "unknown")
                st.metric("ê²€ìƒ‰ íƒ€ì…", search_type.upper())
            
            st.divider()
            
            # ê²°ê³¼ ëª©ë¡
            for i, result in enumerate(results, 1):
                with st.expander(f"ğŸ“„ ê²°ê³¼ {i} - ì ìˆ˜: {result.get('score', 0):.3f}"):
                    col_res1, col_res2 = st.columns([2, 1])
                    
                    with col_res1:
                        content = result.get("content", "ë‚´ìš© ì—†ìŒ")
                        st.write("**ë‚´ìš©:**")
                        st.write(content)
                        
                        # í•˜ì´ë¼ì´íŠ¸ í‘œì‹œ
                        highlights = result.get("highlights")
                        if highlights:
                            st.write("**í•˜ì´ë¼ì´íŠ¸:**")
                            for highlight in highlights[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                                st.markdown(f"ğŸ’¡ {highlight}")
                    
                    with col_res2:
                        metadata = result.get("metadata", {})
                        st.write("**ë©”íƒ€ë°ì´í„°:**")
                        st.write(f"íŒŒì¼ëª…: {metadata.get('filename', 'N/A')}")
                        st.write(f"ì²­í¬ ì¸ë±ìŠ¤: {metadata.get('chunk_index', 'N/A')}")
                        st.write(f"í† í° ìˆ˜: {metadata.get('token_count', 'N/A')}")
                        
                        # ê²€ìƒ‰ ì†ŒìŠ¤ ì •ë³´
                        search_source = result.get("search_source", metadata.get("search_source"))
                        if search_source:
                            st.write(f"ê²€ìƒ‰ ì†ŒìŠ¤: {search_source}")
                        
                        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìˆ˜
                        if "hybrid_score" in metadata:
                            st.write(f"í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: {metadata['hybrid_score']:.3f}")
                            st.write(f"ë²¡í„° ì ìˆ˜: {metadata.get('vector_score', 0):.3f}")
                            st.write(f"í…ìŠ¤íŠ¸ ì ìˆ˜: {metadata.get('text_score', 0):.3f}")
        else:
            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

# íƒ­ 4: AI ì±—ë´‡
with tab4:
    st.header("ğŸ¤– AI ì±—ë´‡")

    # ì±—ë´‡ ì„¤ì •
    with st.expander("ğŸ”§ ì±—ë´‡ ì„¤ì •"):
        col_chat1, col_chat2 = st.columns(2)

        with col_chat1:
            use_search = st.checkbox("ë¬¸ì„œ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€", value=True, key="chat_use_search")
            if use_search:
                search_limit = st.number_input("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", min_value=1, max_value=10, value=5)
                use_rerank = st.checkbox("ë¦¬ë­í‚¹ ì ìš©", value=True, key="chat_rerank")

        with col_chat2:
            temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.0, 1.0, 0.7)
            max_tokens = st.number_input("ìµœëŒ€ í† í° ìˆ˜", min_value=100, max_value=2000, value=500)

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    chat_container = st.container()

    with chat_container:
        for message in st.session_state.chat_history:
            if message["role"] == "user":
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>ğŸ‘¤ ì‚¬ìš©ì:</strong><br>
                    {message["content"]}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message assistant-message">
                    <strong>ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸:</strong><br>
                    {message["content"]}
                </div>
                """, unsafe_allow_html=True)

                # ì°¸ì¡° ë¬¸ì„œ í‘œì‹œ
                if "sources" in message:
                    with st.expander("ğŸ“š ì°¸ì¡° ë¬¸ì„œ"):
                        for i, source in enumerate(message["sources"], 1):
                            st.write(f"**{i}.** {source.get('filename', 'Unknown')} (ì ìˆ˜: {source.get('score', 0):.3f})")
                            st.write(f"ë‚´ìš©: {source.get('content', '')[:200]}...")

    # ì±„íŒ… ì…ë ¥
    user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")

    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                # ë¬¸ì„œ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€
                if use_search:
                    # ë¨¼ì € ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
                    search_data = {
                        "query": user_input,
                        "limit": search_limit,
                        "vector_weight": 0.7,
                        "text_weight": 0.3,
                        "embedding_model": "nlpai-lab/KURE-v1"
                    }

                    if use_rerank:
                        search_data.update({
                            "rerank": True,
                            "rerank_top_k": search_limit * 2
                        })

                    search_result = make_api_request("/v1/search/hybrid", "POST", search_data)

                    if search_result["success"]:
                        search_results = search_result["data"].get("results", [])

                        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                        context = "\n\n".join([
                            f"ë¬¸ì„œ {i+1}: {result.get('content', '')}"
                            for i, result in enumerate(search_results[:3])
                        ])

                        # AI ë‹µë³€ ìƒì„± (ì‹¤ì œë¡œëŠ” OpenAI API ë“±ì„ ì‚¬ìš©í•´ì•¼ í•¨)
                        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
                        if context:
                            ai_response = f"""
ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

**ì§ˆë¬¸:** {user_input}

**ë‹µë³€:**
ì œê³µëœ ë¬¸ì„œë“¤ì„ ë¶„ì„í•œ ê²°ê³¼, ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤:

{context[:500]}...

ì´ ì •ë³´ê°€ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.
                            """

                            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": ai_response,
                                "sources": search_results[:3]
                            })
                        else:
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ë³´ì‹œê² ì–´ìš”?"
                            })
                    else:
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": "ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
                        })
                else:
                    # ì¼ë°˜ AI ë‹µë³€ (ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´)
                    ai_response = f"ì§ˆë¬¸: '{user_input}'ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤. (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLM APIë¥¼ ì—°ë™í•´ì•¼ í•©ë‹ˆë‹¤.)"
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": ai_response
                    })

            except Exception as e:
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                })

        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìƒˆ ë©”ì‹œì§€ í‘œì‹œ
        st.rerun()

    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if st.button("ğŸ—‘ï¸ ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"):
        st.session_state.chat_history = []
        st.rerun()

# íƒ­ 5: ì‹œìŠ¤í…œ í†µê³„
with tab5:
    st.header("ğŸ“ˆ ì‹œìŠ¤í…œ í†µê³„")

    # í†µê³„ ìƒˆë¡œê³ ì¹¨
    if st.button("ğŸ”„ í†µê³„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        with st.spinner("í†µê³„ ë°ì´í„° ë¡œë”© ì¤‘..."):
            # ì €ì¥ì†Œ í†µê³„
            storage_result = make_api_request("/v1/storage/stats")
            if storage_result["success"]:
                st.session_state.storage_stats = storage_result["data"]

            # ëª¨ë‹ˆí„°ë§ í†µê³„
            monitoring_result = make_api_request("/v1/monitoring/stats")
            if monitoring_result["success"]:
                st.session_state.monitoring_stats = monitoring_result["data"]

            # íŒŒì¼ í†µê³„
            files_result = make_api_request("/v1/files", "GET", {"page_size": 1000})
            if files_result["success"]:
                st.session_state.files_stats = files_result["data"]

    # ì €ì¥ì†Œ í†µê³„
    if 'storage_stats' in st.session_state:
        st.subheader("ğŸ’¾ ì €ì¥ì†Œ í†µê³„")

        storage_data = st.session_state.storage_stats.get("stats", {})

        col_storage1, col_storage2, col_storage3, col_storage4 = st.columns(4)

        with col_storage1:
            total_size = storage_data.get("total_size", 0)
            st.metric("ì´ ì €ì¥ì†Œ ì‚¬ìš©ëŸ‰", format_file_size(total_size))

        with col_storage2:
            file_count = storage_data.get("file_count", 0)
            st.metric("ì´ íŒŒì¼ ìˆ˜", file_count)

        with col_storage3:
            avg_size = total_size / max(file_count, 1)
            st.metric("í‰ê·  íŒŒì¼ í¬ê¸°", format_file_size(avg_size))

        with col_storage4:
            directories = storage_data.get("directories", {})
            st.metric("ë””ë ‰í† ë¦¬ ìˆ˜", len(directories))

    # ëª¨ë‹ˆí„°ë§ í†µê³„
    if 'monitoring_stats' in st.session_state:
        st.subheader("ğŸ“Š ëª¨ë‹ˆí„°ë§ í†µê³„")

        monitoring_data = st.session_state.monitoring_stats.get("stats", {})

        col_mon1, col_mon2, col_mon3, col_mon4 = st.columns(4)

        with col_mon1:
            total_requests = monitoring_data.get("total_requests", 0)
            st.metric("ì´ ìš”ì²­ ìˆ˜", total_requests)

        with col_mon2:
            avg_response_time = monitoring_data.get("average_response_time", 0)
            st.metric("í‰ê·  ì‘ë‹µ ì‹œê°„", f"{avg_response_time:.3f}ì´ˆ")

        with col_mon3:
            duplicate_count = monitoring_data.get("duplicate_files_detected", 0)
            st.metric("ì¤‘ë³µ íŒŒì¼ ê°ì§€", duplicate_count)

        with col_mon4:
            space_saved = monitoring_data.get("space_saved_bytes", 0)
            st.metric("ì ˆì•½ëœ ê³µê°„", format_file_size(space_saved))

        # ì„±ëŠ¥ ì°¨íŠ¸
        if "performance_history" in monitoring_data:
            st.subheader("ğŸ“ˆ ì„±ëŠ¥ ì¶”ì´")

            perf_data = monitoring_data["performance_history"]
            if perf_data:
                df = pd.DataFrame(perf_data)

                # ì‘ë‹µ ì‹œê°„ ì°¨íŠ¸
                fig_response = px.line(
                    df,
                    x="timestamp",
                    y="response_time",
                    title="ì‘ë‹µ ì‹œê°„ ì¶”ì´",
                    labels={"response_time": "ì‘ë‹µ ì‹œê°„ (ì´ˆ)", "timestamp": "ì‹œê°„"}
                )
                st.plotly_chart(fig_response, use_container_width=True)

    # íŒŒì¼ íƒ€ì… ë¶„í¬
    if 'files_stats' in st.session_state:
        st.subheader("ğŸ“„ íŒŒì¼ íƒ€ì… ë¶„í¬")

        files = st.session_state.files_stats.get("files", [])
        if files:
            # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
            file_types = {}
            for file_info in files:
                file_type = file_info.get("file_type", "unknown")
                file_types[file_type] = file_types.get(file_type, 0) + 1

            # íŒŒì´ ì°¨íŠ¸
            if file_types:
                fig_pie = px.pie(
                    values=list(file_types.values()),
                    names=list(file_types.keys()),
                    title="íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬"
                )
                st.plotly_chart(fig_pie, use_container_width=True)

            # ìµœê·¼ ì—…ë¡œë“œ íŒŒì¼ë“¤
            st.subheader("ğŸ“… ìµœê·¼ ì—…ë¡œë“œ íŒŒì¼")

            recent_files = sorted(files, key=lambda x: x.get("created_at", 0), reverse=True)[:10]

            if recent_files:
                df_recent = pd.DataFrame([
                    {
                        "íŒŒì¼ëª…": f.get("filename", "Unknown"),
                        "í¬ê¸°": format_file_size(f.get("file_size", f.get("size", 0))),
                        "íƒ€ì…": f.get("file_type", "Unknown"),
                        "ì²˜ë¦¬ ìƒíƒœ": "âœ… ì™„ë£Œ" if f.get("is_processed") else "âŒ ë¯¸ì²˜ë¦¬",
                        "ì¤‘ë³µ": "âš ï¸ ì¤‘ë³µ" if f.get("is_duplicate") else "âœ… ì›ë³¸",
                        "ì—…ë¡œë“œ ì‹œê°„": datetime.fromtimestamp(f.get("created_at", 0)).strftime("%Y-%m-%d %H:%M:%S") if f.get("created_at") else "Unknown"
                    }
                    for f in recent_files
                ])

                st.dataframe(df_recent, use_container_width=True)

    if not any(key in st.session_state for key in ['storage_stats', 'monitoring_stats', 'files_stats']):
        st.info("í†µê³„ë¥¼ ë³´ë ¤ë©´ 'í†µê³„ ìƒˆë¡œê³ ì¹¨' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# í‘¸í„°
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; padding: 1rem;">
    ğŸ” KURE ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ v1.0 |
    Powered by FastAPI + Streamlit |
    <a href="https://github.com/hurxxxx/ragnaforge" target="_blank">GitHub</a>
</div>
""", unsafe_allow_html=True)
