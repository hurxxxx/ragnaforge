# KURE v1 API Gateway - GPU Optimized Configuration
# Copy this to .env and adjust values based on your GPU

# API Configuration
API_KEY=sk-kure-v1-your-secret-key
HOST=0.0.0.0
PORT=8000

# Model Configuration
DEFAULT_MODEL=dragonkue/snowflake-arctic-embed-l-v2.0-ko
CACHE_DIR=./models

# GPU Optimized Batch Settings
MAX_BATCH_SIZE=64
OPTIMAL_BATCH_SIZE=64
MAX_TEXT_LENGTH=8192

# GPU Memory Management
GPU_MEMORY_FRACTION=0.8
CUDA_VISIBLE_DEVICES=0
TORCH_CUDNN_BENCHMARK=true

# Performance Settings
WORKERS=1
MAX_SEQUENCE_LENGTH=512

# Text Chunking Defaults (GPU optimized, research-based)
DEFAULT_CHUNK_STRATEGY=recursive
DEFAULT_CHUNK_SIZE=768
DEFAULT_CHUNK_OVERLAP=100
DEFAULT_CHUNK_LANGUAGE=auto

# Search Defaults (Optimized for hybrid search + rerank workflow)
DEFAULT_SEARCH_LIMIT=100
DEFAULT_SCORE_THRESHOLD=0.0
DEFAULT_VECTOR_WEIGHT=0.7
DEFAULT_TEXT_WEIGHT=0.3
SEARCH_EXPANSION_FACTOR=3

# Rerank Configuration (Optimized for 100â†’50 workflow)
RERANK_ENABLED=true
RERANK_MODEL=dragonkue/bge-reranker-v2-m3-ko
RERANK_MODEL_TYPE=bge_m3_ko
RERANK_TOP_K=300
RERANK_FINAL_K=50
RERANK_BATCH_SIZE=64
RERANK_DEVICE=
RERANK_CACHE_ENABLED=true
RERANK_CACHE_SIZE=2000

# Logging
LOG_LEVEL=INFO

# GPU Specific Settings
# Adjust based on your GPU memory:
# - 8GB GPU: MAX_BATCH_SIZE=32, OPTIMAL_BATCH_SIZE=32
# - 12GB GPU: MAX_BATCH_SIZE=64, OPTIMAL_BATCH_SIZE=64  
# - 16GB+ GPU: MAX_BATCH_SIZE=128, OPTIMAL_BATCH_SIZE=128

# For RTX 3080/3090 (10-24GB):
# MAX_BATCH_SIZE=128
# OPTIMAL_BATCH_SIZE=128

# For RTX 4090 (24GB):
# MAX_BATCH_SIZE=256
# OPTIMAL_BATCH_SIZE=256

# For A100 (40-80GB):
# MAX_BATCH_SIZE=512
# OPTIMAL_BATCH_SIZE=512
