# KURE v1 API Gateway - GPU Optimized Configuration
# Copy this to .env and adjust values based on your GPU

# API Configuration
API_KEY=sk-kure-v1-your-secret-key
HOST=0.0.0.0
PORT=8000

# Model Configuration
DEFAULT_MODEL=dragonkue/snowflake-arctic-embed-l-v2.0-ko
CACHE_DIR=./models

# GPU Optimized Batch Settings
MAX_BATCH_SIZE=64
OPTIMAL_BATCH_SIZE=64
MAX_TEXT_LENGTH=8192

# GPU Memory Management
GPU_MEMORY_FRACTION=0.8
CUDA_VISIBLE_DEVICES=0
TORCH_CUDNN_BENCHMARK=true

# Performance Settings
WORKERS=1
MAX_SEQUENCE_LENGTH=512

# Text Chunking Defaults (GPU optimized)
DEFAULT_CHUNK_STRATEGY=recursive
DEFAULT_CHUNK_SIZE=380
DEFAULT_CHUNK_OVERLAP=70
DEFAULT_CHUNK_LANGUAGE=auto

# Logging
LOG_LEVEL=INFO

# GPU Specific Settings
# Adjust based on your GPU memory:
# - 8GB GPU: MAX_BATCH_SIZE=32, OPTIMAL_BATCH_SIZE=32
# - 12GB GPU: MAX_BATCH_SIZE=64, OPTIMAL_BATCH_SIZE=64  
# - 16GB+ GPU: MAX_BATCH_SIZE=128, OPTIMAL_BATCH_SIZE=128

# For RTX 3080/3090 (10-24GB):
# MAX_BATCH_SIZE=128
# OPTIMAL_BATCH_SIZE=128

# For RTX 4090 (24GB):
# MAX_BATCH_SIZE=256
# OPTIMAL_BATCH_SIZE=256

# For A100 (40-80GB):
# MAX_BATCH_SIZE=512
# OPTIMAL_BATCH_SIZE=512
